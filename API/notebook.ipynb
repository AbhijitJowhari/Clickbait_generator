{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "75a2cfb0",
      "metadata": {},
      "source": [
        "# Importing all the required modules\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "294807f4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d9034417",
      "metadata": {},
      "source": [
        "# Loading the trainng Data !\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24faf8cb",
      "metadata": {
        "id": "24faf8cb"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('train.csv')\n",
        "train_list = []\n",
        "for i in range(len(data)):\n",
        "    if(data['clickbait'][i] ==1):\n",
        "        train_list.append(data['headline'][i])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "86e0c189",
      "metadata": {},
      "source": [
        "# Analysing and stroring the bigrams just for future reference\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "658bb04e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "658bb04e",
        "outputId": "1cb0dadf-6f76-4c4e-fd6b-68a310dc3da5"
      },
      "outputs": [],
      "source": [
        "sentences = train_list[:int(0.20*len(train_list))]\n",
        "b = {}\n",
        "for sent in sentences:\n",
        "  chs = ['<S>'] + sent.split() + ['<E>']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    bigram = (ch1, ch2)\n",
        "    b[bigram] = b.get(bigram, 0) + 1\n",
        "sorted(b.items(), key = lambda kv: -kv[1])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c2fa5442",
      "metadata": {},
      "source": [
        "# Constructing the strings_to_index and inverse dictionaries\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f60f1407",
      "metadata": {
        "id": "f60f1407"
      },
      "outputs": [],
      "source": [
        "words = sorted(list(set((' '.join(sentences)).split())))\n",
        "stoi = {s:i+1 for i,s in enumerate(words)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "351eabd8",
      "metadata": {},
      "source": [
        "# Preparing the training data for our neural network\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f22ed9be",
      "metadata": {
        "id": "f22ed9be"
      },
      "outputs": [],
      "source": [
        "xs, ys = [], []\n",
        "\n",
        "for sent in sentences:\n",
        "  chs = ['.'] + sent.split() + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "83673ba5",
      "metadata": {},
      "source": [
        "# construting the generator object and training the on the data!\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "769921ac",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "num = xs.nelement()\n",
        "g = torch.Generator().manual_seed(1234)\n",
        "\n",
        "W = torch.randn((len(stoi),len(stoi)),generator=g , requires_grad = True)\n",
        "\n",
        "for k in range(90):\n",
        "\n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=len(stoi)).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  W.data += -1200 * W.grad"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "628131a1",
      "metadata": {},
      "source": [
        "# Storing the the trained model\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e668ba1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "txt = 1234\n",
        "joblib.dump(txt,'seed.sav')\n",
        "joblib.dump(stoi,'stoi.sav')\n",
        "joblib.dump(itos,'itos.sav')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
